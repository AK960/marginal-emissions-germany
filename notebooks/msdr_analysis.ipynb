{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MSDR Analysis",
   "id": "39b6dc2610be356e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-04T09:05:05.627909146Z",
     "start_time": "2026-02-04T09:05:05.576750120Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from joblib import Parallel, delayed\n"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T09:03:15.808740903Z",
     "start_time": "2026-02-04T09:03:15.219568362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "regional_emissions_final = {\n",
    "    'f_hertz': pd.read_csv('../data/processed/analysis_final_f_hertz_15min_utc_202212312300_202412312245', sep=',', index_col=0),\n",
    "    'amprion': pd.read_csv('../data/processed/analysis_final_amprion_15min_utc_202212312300_202412312245', sep=',', index_col=0),\n",
    "    'tennet': pd.read_csv('../data/processed/analysis_final_tennet_15min_utc_202212312300_202412312245', sep=',', index_col=0),\n",
    "    'transnetbw': pd.read_csv('../data/processed/analysis_final_transnet_bw_15min_utc_202212312300_202412312245', sep=',', index_col=0)\n",
    "}\n",
    "\n",
    "for df in regional_emissions_final.values():\n",
    "    df.index = pd.to_datetime(df.index, format='ISO8601')\n",
    "    df.sort_index(inplace=True)\n",
    "    if df.index.tz is None:\n",
    "        try:\n",
    "            df.index = df.index.tz_localize('Europe/Berlin', ambiguous='infer')\n",
    "        except pytz.exceptions.AmbiguousTimeError:\n",
    "            df.index = df.index.tz_localize('Europe/Berlin', ambiguous=True)\n",
    "        df.index = df.index.tz_convert('UTC')"
   ],
   "id": "40028cc18d15db6c",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preparing Analysis Dataframe",
   "id": "4bf4341e62bdc33d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T09:03:15.911708126Z",
     "start_time": "2026-02-04T09:03:15.847208992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data inspection\n",
    "print(\"I. DATA INSPECTION\")\n",
    "print(\"-\"*20, \"Checking for unwanted values\", \"-\"*20)\n",
    "for name, reg in regional_emissions_final.items():\n",
    "    print(f\"[{name}]\")\n",
    "    print(f\"  1) Index data type: {reg.index.dtype}\")\n",
    "    print(f\"  2) Duplicate Entries: {(reg.index.duplicated()).sum()}\")\n",
    "    print(f\"  3) Negative Values for Generation: {(reg['total_generation'] < 0).sum()}\")\n",
    "    print(f\"  4) Rows with NaN Values: {(reg.isnull().sum()).sum()}\")\n"
   ],
   "id": "1eb682da9e0366d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I. DATA INSPECTION\n",
      "-------------------- Checking for unwandet values --------------------\n",
      "[f_hertz]\n",
      "  1) Index data type: datetime64[ns, UTC]\n",
      "  2) Duplicate Entries: 0\n",
      "  3) Negative Values for Generation: 0\n",
      "  4) Rows with NaN Values: 0\n",
      "[amprion]\n",
      "  1) Index data type: datetime64[ns, UTC]\n",
      "  2) Duplicate Entries: 0\n",
      "  3) Negative Values for Generation: 0\n",
      "  4) Rows with NaN Values: 0\n",
      "[tennet]\n",
      "  1) Index data type: datetime64[ns, UTC]\n",
      "  2) Duplicate Entries: 0\n",
      "  3) Negative Values for Generation: 0\n",
      "  4) Rows with NaN Values: 0\n",
      "[transnetbw]\n",
      "  1) Index data type: datetime64[ns, UTC]\n",
      "  2) Duplicate Entries: 0\n",
      "  3) Negative Values for Generation: 0\n",
      "  4) Rows with NaN Values: 0\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T09:03:16.022448235Z",
     "start_time": "2026-02-04T09:03:15.912637481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data preparation\n",
    "analysis_dfs = {}\n",
    "\n",
    "print(\"II. DATA PREPARATION\")\n",
    "for name, reg in regional_emissions_final.items():\n",
    "    print(f\"[{name}]\")\n",
    "    print(f\"  1) Calculation delta for time series:\")\n",
    "\n",
    "    # Calculating the delta between two consecutive rows to eliminate trends\n",
    "    delta_reg = reg - reg.shift(1)\n",
    "    delta_reg = delta_reg[1:] # Dropping the first row will be NaN\n",
    "    print(delta_reg.head(3))\n",
    "\n",
    "    # Scaling data to have zero mean and unit variance (z-transformation)\n",
    "    print(f\"  2) Scaling data to have zero mean and unit variance:\")\n",
    "    scaler = StandardScaler()\n",
    "    delta_reg[['total_generation', 'total_emissions']] = scaler.fit_transform(delta_reg[['total_generation', 'total_emissions']]) # Apply to cols to keep df\n",
    "    print(delta_reg.head(3))\n",
    "\n",
    "    # After transformation, check for missing values again\n",
    "    print(f\"  3) Rows with NaN Values after Transformation: {(delta_reg.isnull().sum()).sum()}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Add transformed dfs to dict to access later\n",
    "    analysis_dfs[name] = delta_reg\n"
   ],
   "id": "c1bd363d09d2a36d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "II. DATA PREPARATION\n",
      "[f_hertz]\n",
      "  1) Calculation delta for time series:\n",
      "                           total_generation  total_emissions\n",
      "datetime                                                    \n",
      "2022-12-31 23:15:00+00:00               0.0             0.19\n",
      "2022-12-31 23:30:00+00:00               4.5             5.64\n",
      "2022-12-31 23:45:00+00:00              -4.0            -4.90\n",
      "  2) Scaling data to have zero mean and unit variance:\n",
      "                           total_generation  total_emissions\n",
      "datetime                                                    \n",
      "2022-12-31 23:15:00+00:00         -0.000090         0.004570\n",
      "2022-12-31 23:30:00+00:00          0.142073         0.124951\n",
      "2022-12-31 23:45:00+00:00         -0.126457        -0.107859\n",
      "  3) Rows with NaN Values after Transformation: 0\n",
      "\n",
      "\n",
      "[amprion]\n",
      "  1) Calculation delta for time series:\n",
      "                           total_generation  total_emissions\n",
      "datetime                                                    \n",
      "2022-12-31 23:15:00+00:00             -4.50            -6.74\n",
      "2022-12-31 23:30:00+00:00              1.75             3.32\n",
      "2022-12-31 23:45:00+00:00             -3.75            -5.34\n",
      "  2) Scaling data to have zero mean and unit variance:\n",
      "                           total_generation  total_emissions\n",
      "datetime                                                    \n",
      "2022-12-31 23:15:00+00:00         -0.079235        -0.124740\n",
      "2022-12-31 23:30:00+00:00          0.030812         0.061849\n",
      "2022-12-31 23:45:00+00:00         -0.066030        -0.098773\n",
      "  3) Rows with NaN Values after Transformation: 0\n",
      "\n",
      "\n",
      "[tennet]\n",
      "  1) Calculation delta for time series:\n",
      "                           total_generation  total_emissions\n",
      "datetime                                                    \n",
      "2022-12-31 23:15:00+00:00               0.0              0.0\n",
      "2022-12-31 23:30:00+00:00               0.0              0.0\n",
      "2022-12-31 23:45:00+00:00               0.0              0.0\n",
      "  2) Scaling data to have zero mean and unit variance:\n",
      "                           total_generation  total_emissions\n",
      "datetime                                                    \n",
      "2022-12-31 23:15:00+00:00         -0.000113         0.000289\n",
      "2022-12-31 23:30:00+00:00         -0.000113         0.000289\n",
      "2022-12-31 23:45:00+00:00         -0.000113         0.000289\n",
      "  3) Rows with NaN Values after Transformation: 0\n",
      "\n",
      "\n",
      "[transnetbw]\n",
      "  1) Calculation delta for time series:\n",
      "                           total_generation  total_emissions\n",
      "datetime                                                    \n",
      "2022-12-31 23:15:00+00:00              0.50             0.43\n",
      "2022-12-31 23:30:00+00:00              0.25             0.21\n",
      "2022-12-31 23:45:00+00:00             -0.25            -0.21\n",
      "  2) Scaling data to have zero mean and unit variance:\n",
      "                           total_generation  total_emissions\n",
      "datetime                                                    \n",
      "2022-12-31 23:15:00+00:00          0.042923         0.036224\n",
      "2022-12-31 23:30:00+00:00          0.021151         0.017819\n",
      "2022-12-31 23:45:00+00:00         -0.022393        -0.017317\n",
      "  3) Rows with NaN Values after Transformation: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Performing MSDR Analysis",
   "id": "d42528ad4b910915"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Defining model params and vars\n",
    "\n",
    "# Using a rolling time window to allow for the model to adjust over time\n",
    "win_len = 7*24*4 # size of the time window (1 week = 672 values for 15-min data)\n",
    "\n",
    "# Simplified Parameter Grid\n",
    "# Removed regularization/penalty as discussed.\n",
    "# Removed 'exog' from grid: we ALWAYS want to use generation to calculate MEF.\n",
    "param_grid = {\n",
    "    'k_regimes': [2, 3],                 # Number of regimes\n",
    "    'switching_variance': [True, False], # Whether variance switches between regimes\n",
    "    'trend': ['c', 't'],                 # c = intercept, t = time trend\n",
    "}\n",
    "\n",
    "def fit_markov_model(ret_window, params):\n",
    "    try:\n",
    "        # We always use total_generation as exogenous variable to determine MEF\n",
    "        msdr_model = sm.tsa.MarkovRegression(\n",
    "            endog=ret_window['total_emissions'],\n",
    "            k_regimes=params['k_regimes'],\n",
    "            trend=params['trend'],\n",
    "            exog=ret_window[['total_generation']], # Always include Generation\n",
    "            switching_variance=params['switching_variance']\n",
    "        )\n",
    "\n",
    "        msdr_result = msdr_model.fit(disp=False)\n",
    "\n",
    "        # Predict within sample to calculate error\n",
    "        msdr_predict = msdr_result.predict(start=ret_window.index[0], end=ret_window.index[-1])\n",
    "\n",
    "        # Compute MAE (Mean Absolute Error)\n",
    "        mae = np.mean(np.abs(ret_window['total_emissions'] - msdr_predict))\n",
    "\n",
    "        return msdr_result, msdr_result.aic, mae\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Model fitting failed for parameters: {params} with error: {e}\")\n",
    "        return None, np.inf, np.inf\n",
    "\n",
    "# Function to process one window\n",
    "def process_window(i, data, grid):\n",
    "    reg_win = data.iloc[i:i+win_len]\n",
    "    best_result = None\n",
    "    best_mae = np.inf\n",
    "\n",
    "    for params in ParameterGrid(grid):\n",
    "        result, aic, mae = fit_markov_model(reg_win, params)\n",
    "        if mae < best_mae:\n",
    "            best_result = result\n",
    "            best_mae = mae\n",
    "\n",
    "    return best_result\n",
    "\n",
    "# Select which region to analyze (e.g., 'tennet') or loop over them\n",
    "# For now, let's pick one to demonstrate. You can change this key.\n",
    "current_region_name = 'tennet'\n",
    "current_data = analysis_dfs[current_region_name]\n",
    "\n",
    "print(f\"Starting analysis for {current_region_name} with {len(current_data)} rows...\")\n",
    "\n",
    "# Run Parallel execution\n",
    "# Note: We pass 'current_data' and 'param_grid' explicitly to avoid scope issues\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(process_window)(i, current_data, param_grid)\n",
    "    for i in range(len(current_data) - win_len + 1)\n",
    ")\n",
    "\n",
    "print(\"Analysis complete.\")\n"
   ],
   "id": "689e8e1c5c351142"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Estimate the emission time series using the best model for each window\n",
    "# Using current_data (make sure it matches the region analyzed above)\n",
    "estimated_emi = current_data[['total_emissions']].copy()\n",
    "estimated_emi['estimated_emissions'] = np.nan\n",
    "\n",
    "for i in range(len(current_data)-win_len+1):\n",
    "    reg_win = current_data.iloc[i:i+win_len]\n",
    "    msdr_results = results[i]\n",
    "\n",
    "    if msdr_results is not None:\n",
    "        forecast = msdr_results.predict(start=reg_win.index[-1], end=reg_win.index[-1])\n",
    "        estimated_emi.loc[reg_win.index[-1], 'estimated_emissions'] = forecast[0]\n",
    "    else:\n",
    "        pass\n",
    "        # print(f\"Model fitting failed for window ending {reg_win.index[-1]}\")\n",
    "\n",
    "print(\"Estimation complete. Head of results:\")\n",
    "print(estimated_emi.head())\n"
   ],
   "id": "5bee2788ae5bfce9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
