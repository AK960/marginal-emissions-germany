{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MSDR Analysis",
   "id": "39b6dc2610be356e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from joblib import Parallel, delayed\n",
    "from statsmodels.tools.sm_exceptions import ValueWarning, ConvergenceWarning\n",
    "\n",
    "# Suppress specific statsmodels warnings\n",
    "warnings.simplefilter('ignore', ValueWarning)\n",
    "# Suppress ConvergenceWarning to avoid cluttering output during rolling window\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "# Suppress RuntimeWarning from numpy which often happens during optimization of unstable models\n",
    "warnings.simplefilter('ignore', RuntimeWarning)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "regional_emissions_final = {\n",
    "    'f_hertz': pd.read_csv('../data/processed/analysis_final_f_hertz_15min_utc_202212312300_202412312245', sep=',', index_col=0),\n",
    "    'amprion': pd.read_csv('../data/processed/analysis_final_amprion_15min_utc_202212312300_202412312245', sep=',', index_col=0),\n",
    "    'tennet': pd.read_csv('../data/processed/analysis_final_tennet_15min_utc_202212312300_202412312245', sep=',', index_col=0),\n",
    "    'transnetbw': pd.read_csv('../data/processed/analysis_final_transnet_bw_15min_utc_202212312300_202412312245', sep=',', index_col=0)\n",
    "}\n",
    "\n",
    "for df in regional_emissions_final.values():\n",
    "    df.index = pd.to_datetime(df.index, format='ISO8601')\n",
    "    df.sort_index(inplace=True)\n",
    "    if df.index.tz is None:\n",
    "        try:\n",
    "            df.index = df.index.tz_localize('Europe/Berlin', ambiguous='infer')\n",
    "        except pytz.exceptions.AmbiguousTimeError:\n",
    "            df.index = df.index.tz_localize('Europe/Berlin', ambiguous=True)\n",
    "        df.index = df.index.tz_convert('UTC')\n",
    "\n",
    "    # Explicitly set frequency to 15 minutes\n",
    "    df = df.asfreq('15min')\n"
   ],
   "id": "40028cc18d15db6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preparing Analysis Dataframe",
   "id": "4bf4341e62bdc33d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Data inspection\n",
    "print(\"I. DATA INSPECTION\")\n",
    "print(\"-\"*20, \"Checking for unwanted values\", \"-\"*20)\n",
    "for name, reg in regional_emissions_final.items():\n",
    "    print(f\"[{name}]\")\n",
    "    print(f\"  1) Index data type: {reg.index.dtype}\")\n",
    "    print(f\"  2) Duplicate Entries: {(reg.index.duplicated()).sum()}\")\n",
    "    print(f\"  3) Negative Values for Generation: {(reg['total_generation'] < 0).sum()}\")\n",
    "    print(f\"  4) Rows with NaN Values: {(reg.isnull().sum()).sum()}\")\n"
   ],
   "id": "1eb682da9e0366d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Data preparation\n",
    "analysis_dfs = {}\n",
    "\n",
    "print(\"II. DATA PREPARATION\")\n",
    "for name, reg in regional_emissions_final.items():\n",
    "    print(f\"[{name}]\")\n",
    "    print(f\"  1) Calculation delta for time series:\")\n",
    "\n",
    "    # Calculating the delta between two consecutive rows to eliminate trends\n",
    "    delta_reg = reg - reg.shift(1)\n",
    "    delta_reg = delta_reg[1:] # Dropping the first row will be NaN\n",
    "\n",
    "    # Ensure frequency is set after shifting/dropping\n",
    "    delta_reg = delta_reg.asfreq('15min')\n",
    "\n",
    "    # Fill any NaNs created by asfreq (if gaps existed) or shift\n",
    "    if delta_reg.isnull().values.any():\n",
    "        # Interpolate is often better than ffill for physical time series\n",
    "        delta_reg = delta_reg.interpolate(method='time')\n",
    "        # If NaNs remain (e.g. at start), drop them\n",
    "        delta_reg = delta_reg.dropna()\n",
    "\n",
    "    print(delta_reg.head(3))\n",
    "\n",
    "    # Scaling data to have zero mean and unit variance (z-transformation)\n",
    "    print(f\"  2) Scaling data to have zero mean and unit variance:\")\n",
    "    scaler = StandardScaler()\n",
    "    delta_reg[['total_generation', 'total_emissions']] = scaler.fit_transform(delta_reg[['total_generation', 'total_emissions']]) # Apply to cols to keep df\n",
    "    print(delta_reg.head(3))\n",
    "\n",
    "    # After transformation, check for missing values again\n",
    "    print(f\"  3) Rows with NaN Values after Transformation: {(delta_reg.isnull().sum()).sum()}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Add transformed dfs to dict to access later\n",
    "    analysis_dfs[name] = delta_reg\n"
   ],
   "id": "c1bd363d09d2a36d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Performing MSDR Analysis",
   "id": "d42528ad4b910915"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Defining model params and vars\n",
    "\n",
    "# Using a rolling time window to allow for the model to adjust over time\n",
    "win_len = 7*24*4 # size of the time window (1 week = 672 values for 15-min data)\n",
    "\n",
    "# Simplified Parameter Grid\n",
    "param_grid = {\n",
    "    'k_regimes': [2, 3],                 # Number of regimes\n",
    "    'switching_variance': [True, False], # Whether variance switches between regimes\n",
    "    'trend': ['c', 't'],                 # c = intercept, t = time trend\n",
    "}\n",
    "\n",
    "def fit_markov_model(ret_window, params):\n",
    "    try:\n",
    "        # We always use total_generation as exogenous variable to determine MEF\n",
    "        msdr_model = sm.tsa.MarkovRegression(\n",
    "            endog=ret_window['total_emissions'],\n",
    "            k_regimes=params['k_regimes'],\n",
    "            trend=params['trend'],\n",
    "            exog=ret_window[['total_generation']], # Always include Generation\n",
    "            switching_variance=params['switching_variance']\n",
    "        )\n",
    "\n",
    "        # Increased maxiter to help convergence\n",
    "        msdr_result = msdr_model.fit(disp=False, maxiter=200)\n",
    "\n",
    "        # Predict within sample to calculate error\n",
    "        msdr_predict = msdr_result.predict(start=ret_window.index[0], end=ret_window.index[-1])\n",
    "\n",
    "        # Compute MAE (Mean Absolute Error)\n",
    "        mae = np.mean(np.abs(ret_window['total_emissions'] - msdr_predict))\n",
    "\n",
    "        return msdr_result, msdr_result.aic, mae\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Model fitting failed for parameters: {params} with error: {e}\")\n",
    "        return None, np.inf, np.inf\n",
    "\n",
    "# Function to process one window\n",
    "def process_window(i, data, grid):\n",
    "    roll_win = data.iloc[i:i+win_len]\n",
    "\n",
    "    # Ensure window has frequency set\n",
    "    if roll_win.index.freq is None:\n",
    "        roll_win = roll_win.asfreq('15min')\n",
    "\n",
    "    best_result = None\n",
    "    best_mae = np.inf\n",
    "\n",
    "    for params in ParameterGrid(grid):\n",
    "        result, aic, mae = fit_markov_model(roll_win, params)\n",
    "        if mae < best_mae:\n",
    "            best_result = result\n",
    "            best_mae = mae\n",
    "\n",
    "    return best_result\n",
    "\n",
    "# Select which region to analyze (e.g., 'tennet') or loop over them\n",
    "current_region_name = 'tennet'\n",
    "current_data = analysis_dfs[current_region_name]\n",
    "\n",
    "print(f\"Starting analysis for {current_region_name} with {len(current_data)} rows...\")\n",
    "\n",
    "# Run Parallel execution\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(process_window)(i, current_data, param_grid)\n",
    "    for i in range(len(current_data) - win_len + 1)\n",
    ")\n",
    "\n",
    "print(\"Analysis complete.\")\n"
   ],
   "id": "689e8e1c5c351142",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Estimate the emission time series using the best model for each window\n",
    "estimated_emi = current_data[['total_emissions']].copy()\n",
    "estimated_emi['estimated_emissions'] = np.nan\n",
    "\n",
    "for i in range(len(current_data)-win_len+1):\n",
    "    reg_win = current_data.iloc[i:i+win_len]\n",
    "    msdr_results = results[i]\n",
    "\n",
    "    if msdr_results is not None:\n",
    "        forecast = msdr_results.predict(start=reg_win.index[-1], end=reg_win.index[-1])\n",
    "        estimated_emi.loc[reg_win.index[-1], 'estimated_emissions'] = forecast[0]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(\"Estimation complete. Head of results:\")\n",
    "print(estimated_emi.head())\n"
   ],
   "id": "5bee2788ae5bfce9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
